{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks Evaluation\n",
    "\n",
    "Evaluate robustness of baseline and lottery tickets under adversarial attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from src.utils.config import load_config, get_device\n",
    "from src.models.deep_hedging import DeepHedgingNetwork\n",
    "from src.data.preprocessor import create_dataloaders\n",
    "from src.evaluation.metrics import evaluate_robustness\n",
    "from src.utils.visualization import plot_robustness_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Auto-detected device: cpu\n",
      " Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "config = load_config('../config.yaml')\n",
    "device = get_device(config)\n",
    "\n",
    "# Load test data\n",
    "S_test = np.load('../data/processed/S_test.npy')\n",
    "v_test = np.load('../data/processed/v_test.npy')\n",
    "Z_test = np.load('../data/processed/Z_test.npy')\n",
    "\n",
    "# Dummy train/val for dataloader\n",
    "S_train = np.load('../data/processed/S_train.npy')[:1000]\n",
    "v_train = np.load('../data/processed/v_train.npy')[:1000]\n",
    "Z_train = np.load('../data/processed/Z_train.npy')[:1000]\n",
    "\n",
    "batch_size = config['training']['batch_size'] or 256\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    S_train, v_train, Z_train, S_train, v_train, Z_train, S_test, v_test, Z_test,\n",
    "    batch_size, config['compute']['num_parallel_workers']\n",
    ")\n",
    "\n",
    "K = config['data']['heston']['K']\n",
    "T = config['data']['T']\n",
    "dt = config['data']['dt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {}\n",
    "\n",
    "# Baseline dense\n",
    "model_dense = DeepHedgingNetwork(config['model'])\n",
    "model_dense.load_state_dict(torch.load('../experiments/baseline/best_model.pt', map_location=device))\n",
    "model_dense = model_dense.to(device)\n",
    "models_to_test['dense_baseline'] = model_dense\n",
    "\n",
    "# Sparse tickets (if available)\n",
    "for sparsity in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    model_path = f'../experiments/pruning/sparsity_{int(sparsity*100)}/model.pt'\n",
    "    try:\n",
    "        model_sparse = DeepHedgingNetwork(config['model'])\n",
    "        model_sparse.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model_sparse = model_sparse.to(device)\n",
    "        models_to_test[f'ticket_{int(sparsity*100)}'] = model_sparse\n",
    "    except:\n",
    "        print(f\"Model for sparsity {sparsity} not found, skipping\")\n",
    "\n",
    "print(f\"Loaded {len(models_to_test)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_attacks = {}\n",
    "\n",
    "for model_name, model in models_to_test.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    results = evaluate_robustness(model, test_loader, config, K, T, dt, device)\n",
    "    results_attacks[model_name] = results\n",
    "    \n",
    "    print(f\"  Clean CVaR: {results['clean']['cvar_005']:.6f}\")\n",
    "    print(f\"  FGSM CVaR: {results['fgsm']['cvar_005']:.6f}\")\n",
    "    print(f\"  PGD-10 CVaR: {results['pgd10']['cvar_005']:.6f}\")\n",
    "    print(f\"  Robustness Gap (PGD-10): {results['robustness_gap_pgd10']:.6f}\")\n",
    "\n",
    "# Save results\n",
    "with open('../experiments/adversarial/attack_results.json', 'w') as f:\n",
    "    json.dump(results_attacks, f, indent=2)\n",
    "\n",
    "print(\"\\nResults saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(results_attacks.keys())\n",
    "clean_cvars = [results_attacks[m]['clean']['cvar_005'] for m in model_names]\n",
    "fgsm_cvars = [results_attacks[m]['fgsm']['cvar_005'] for m in model_names]\n",
    "pgd_cvars = [results_attacks[m]['pgd10']['cvar_005'] for m in model_names]\n",
    "\n",
    "plot_robustness_comparison(\n",
    "    model_names,\n",
    "    clean_cvars,\n",
    "    fgsm_cvars,\n",
    "    pgd_cvars,\n",
    "    title=\"Robustness Comparison: Clean vs FGSM vs PGD\",\n",
    "    save_path='../figures/robustness_comparison.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Standard lottery tickets are vulnerable to adversarial attacks. Robustness gap increases with sparsity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_robust_lth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
