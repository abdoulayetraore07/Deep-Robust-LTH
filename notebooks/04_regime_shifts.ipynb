{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime Shifts Analysis\n",
    "\n",
    "Test model generalization across different market regimes (calm, high volatility, extreme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.utils.config import load_config, get_device\n",
    "from src.models.deep_hedging import create_model\n",
    "from src.models.losses import create_loss_function\n",
    "from src.data.heston import HestonSimulator, get_or_generate_dataset\n",
    "from src.data.preprocessor import create_dataloaders, compute_features\n",
    "from src.evaluation.metrics import compute_all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../configs/config.yaml')\n",
    "device = get_device(config)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Extract key parameters\n",
    "heston_config = config['data']['heston']\n",
    "K = heston_config['K']\n",
    "T = config['data']['T']\n",
    "n_steps = config['data']['n_steps']\n",
    "dt = T / n_steps\n",
    "\n",
    "print(f\"K={K}, T={T}, n_steps={n_steps}, dt={dt:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Market Regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of paths per regime\n",
    "n_paths_per_regime = 10000\n",
    "\n",
    "# Define regime parameters\n",
    "regime_params = {\n",
    "    'calm': {\n",
    "        'theta': heston_config.get('theta', 0.0398),  # Long-term variance\n",
    "        'xi': heston_config.get('xi', 0.5751),        # Vol of vol\n",
    "        'v_0': heston_config.get('v_0', 0.0175),      # Initial variance\n",
    "        'description': 'Normal market conditions'\n",
    "    },\n",
    "    'high_vol': {\n",
    "        'theta': 0.08,   # 2x baseline long-term variance\n",
    "        'xi': 0.8,       # Higher vol of vol\n",
    "        'v_0': 0.04,     # Higher initial variance\n",
    "        'description': 'High volatility regime (e.g., market stress)'\n",
    "    },\n",
    "    'extreme': {\n",
    "        'theta': 0.15,   # ~4x baseline\n",
    "        'xi': 1.2,       # Very high vol of vol\n",
    "        'v_0': 0.08,     # High initial variance\n",
    "        'description': 'Extreme regime (e.g., crisis)'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Market Regimes:\")\n",
    "for regime_name, params in regime_params.items():\n",
    "    print(f\"\\n{regime_name}:\")\n",
    "    print(f\"  theta (long-term var): {params['theta']}\")\n",
    "    print(f\"  xi (vol of vol):       {params['xi']}\")\n",
    "    print(f\"  v_0 (initial var):     {params['v_0']}\")\n",
    "    print(f\"  Description: {params['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Regime Shift Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regimes_data = {}\n",
    "\n",
    "for regime_name, params in regime_params.items():\n",
    "    print(f\"\\nGenerating {regime_name} regime ({n_paths_per_regime} paths)...\")\n",
    "    \n",
    "    # Create modified Heston parameters\n",
    "    heston_modified = deepcopy(heston_config)\n",
    "    heston_modified['theta'] = params['theta']\n",
    "    heston_modified['xi'] = params['xi']\n",
    "    heston_modified['v_0'] = params['v_0']\n",
    "    \n",
    "    # Simulate\n",
    "    simulator = HestonSimulator(heston_modified)\n",
    "    seed = hash(regime_name) % 10000  # Deterministic seed per regime\n",
    "    S, v = simulator.simulate(n_paths_per_regime, T, n_steps, seed=seed)\n",
    "    \n",
    "    # Compute payoffs\n",
    "    Z = np.maximum(S[:, -1] - K, 0)  # Call payoff\n",
    "    \n",
    "    regimes_data[regime_name] = {\n",
    "        'S': S,\n",
    "        'v': v,\n",
    "        'Z': Z\n",
    "    }\n",
    "    \n",
    "    print(f\"  S range: [{S.min():.2f}, {S.max():.2f}]\")\n",
    "    print(f\"  v range: [{v.min():.6f}, {v.max():.6f}]\")\n",
    "    print(f\"  ITM ratio: {np.mean(S[:, -1] > K) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nAll regimes generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "loss_fn = create_loss_function(config)\n",
    "\n",
    "# Dense baseline\n",
    "baseline_path = Path('../experiments/baseline/checkpoints/best.pt')\n",
    "if baseline_path.exists():\n",
    "    model_dense = create_model(config)\n",
    "    checkpoint = torch.load(baseline_path, map_location=device)\n",
    "    model_dense.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model_dense = model_dense.to(device)\n",
    "    models['dense'] = model_dense\n",
    "    print(f\"Loaded dense baseline\")\n",
    "else:\n",
    "    print(f\"Dense baseline not found at {baseline_path}\")\n",
    "\n",
    "# Sparse ticket 80%\n",
    "ticket_path = Path('../experiments/pruning/sparsity_80/checkpoints/best.pt')\n",
    "if ticket_path.exists():\n",
    "    model_ticket = create_model(config)\n",
    "    checkpoint = torch.load(ticket_path, map_location=device)\n",
    "    model_ticket.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model_ticket = model_ticket.to(device)\n",
    "    models['ticket_80%'] = model_ticket\n",
    "    print(f\"Loaded ticket 80%\")\n",
    "else:\n",
    "    print(f\"Ticket 80% not found, skipping\")\n",
    "\n",
    "# Adversarially trained model\n",
    "adv_path = Path('../experiments/adversarial_training/checkpoints/best.pt')\n",
    "if adv_path.exists():\n",
    "    model_adv = create_model(config)\n",
    "    checkpoint = torch.load(adv_path, map_location=device)\n",
    "    model_adv.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model_adv = model_adv.to(device)\n",
    "    models['robust_ticket'] = model_adv\n",
    "    print(f\"Loaded robust ticket\")\n",
    "else:\n",
    "    print(f\"Robust ticket not found, skipping\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_regime(model, loss_fn, S, v, Z, config, device, batch_size=256):\n",
    "    \"\"\"\n",
    "    Evaluate model on a specific regime's data.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    heston_config = config['data']['heston']\n",
    "    K = heston_config['K']\n",
    "    T = config['data']['T']\n",
    "    n_steps = config['data']['n_steps']\n",
    "    dt = T / n_steps\n",
    "    \n",
    "    model.eval()\n",
    "    all_pnl = []\n",
    "    \n",
    "    # Create simple batches\n",
    "    n_samples = S.shape[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, n_samples)\n",
    "            \n",
    "            S_batch = torch.tensor(S[i:end_idx], dtype=torch.float32, device=device)\n",
    "            v_batch = torch.tensor(v[i:end_idx], dtype=torch.float32, device=device)\n",
    "            Z_batch = torch.tensor(Z[i:end_idx], dtype=torch.float32, device=device)\n",
    "            \n",
    "            features = compute_features(S_batch, v_batch, K, T, dt)\n",
    "            deltas, y = model(features, S_batch)\n",
    "            pnl = loss_fn.compute_pnl(deltas, S_batch, Z_batch, dt)\n",
    "            \n",
    "            all_pnl.append(pnl.cpu())\n",
    "    \n",
    "    all_pnl = torch.cat(all_pnl).numpy()\n",
    "    return compute_all_metrics(all_pnl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Across Regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_regimes = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    results_regimes[model_name] = {}\n",
    "    \n",
    "    for regime_name, data in regimes_data.items():\n",
    "        print(f\"  Regime: {regime_name}...\", end=\" \")\n",
    "        \n",
    "        metrics = evaluate_on_regime(\n",
    "            model, loss_fn,\n",
    "            data['S'], data['v'], data['Z'],\n",
    "            config, device\n",
    "        )\n",
    "        \n",
    "        results_regimes[model_name][regime_name] = metrics\n",
    "        print(f\"CVaR={metrics['cvar_05']:.4f}, Sharpe={metrics['sharpe_ratio']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "output_dir = Path('../experiments/regime_shifts')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_dir / 'results.json', 'w') as f:\n",
    "    json.dump(results_regimes, f, indent=2, default=float)\n",
    "\n",
    "print(f\"\\nResults saved to {output_dir / 'results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Performance Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE DEGRADATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "degradation_results = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    baseline_cvar = results_regimes[model_name]['calm']['cvar_05']\n",
    "    baseline_sharpe = results_regimes[model_name]['calm']['sharpe_ratio']\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Baseline (calm): CVaR={baseline_cvar:.4f}, Sharpe={baseline_sharpe:.4f}\")\n",
    "    \n",
    "    degradation_results[model_name] = {}\n",
    "    \n",
    "    for regime_name in ['high_vol', 'extreme']:\n",
    "        regime_cvar = results_regimes[model_name][regime_name]['cvar_05']\n",
    "        regime_sharpe = results_regimes[model_name][regime_name]['sharpe_ratio']\n",
    "        \n",
    "        # Compute degradation (negative = worse)\n",
    "        cvar_degradation = ((regime_cvar - baseline_cvar) / abs(baseline_cvar)) * 100\n",
    "        sharpe_degradation = ((regime_sharpe - baseline_sharpe) / abs(baseline_sharpe + 1e-8)) * 100\n",
    "        \n",
    "        degradation_results[model_name][regime_name] = {\n",
    "            'cvar_degradation_pct': cvar_degradation,\n",
    "            'sharpe_degradation_pct': sharpe_degradation\n",
    "        }\n",
    "        \n",
    "        print(f\"  {regime_name}: CVaR={regime_cvar:.4f} ({cvar_degradation:+.1f}%), \"\n",
    "              f\"Sharpe={regime_sharpe:.4f} ({sharpe_degradation:+.1f}%)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Performance Across Regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(models) > 0:\n",
    "    regimes_list = ['calm', 'high_vol', 'extreme']\n",
    "    model_names_list = list(models.keys())\n",
    "    n_models = len(model_names_list)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    x = np.arange(len(regimes_list))\n",
    "    width = 0.8 / n_models\n",
    "    colors = ['#2563eb', '#16a34a', '#dc2626', '#9333ea'][:n_models]\n",
    "    \n",
    "    # CVaR across regimes\n",
    "    for i, model_name in enumerate(model_names_list):\n",
    "        cvars = [results_regimes[model_name][r]['cvar_05'] for r in regimes_list]\n",
    "        axes[0].bar(x + i * width - (n_models - 1) * width / 2, cvars, width, \n",
    "                   label=model_name, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    axes[0].set_xlabel('Market Regime')\n",
    "    axes[0].set_ylabel('CVaR 5%')\n",
    "    axes[0].set_title('CVaR Across Market Regimes')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(['Calm', 'High Vol', 'Extreme'])\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Sharpe across regimes\n",
    "    for i, model_name in enumerate(model_names_list):\n",
    "        sharpes = [results_regimes[model_name][r]['sharpe_ratio'] for r in regimes_list]\n",
    "        axes[1].bar(x + i * width - (n_models - 1) * width / 2, sharpes, width, \n",
    "                   label=model_name, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    axes[1].set_xlabel('Market Regime')\n",
    "    axes[1].set_ylabel('Sharpe Ratio')\n",
    "    axes[1].set_title('Sharpe Ratio Across Market Regimes')\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(['Calm', 'High Vol', 'Extreme'])\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/regime_shifts_performance.pdf', dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No models to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Degradation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(degradation_results) > 0:\n",
    "    # Create degradation matrix\n",
    "    model_names_list = list(degradation_results.keys())\n",
    "    regimes_stressed = ['high_vol', 'extreme']\n",
    "    \n",
    "    matrix = np.zeros((len(model_names_list), len(regimes_stressed)))\n",
    "    \n",
    "    for i, model_name in enumerate(model_names_list):\n",
    "        for j, regime in enumerate(regimes_stressed):\n",
    "            matrix[i, j] = degradation_results[model_name][regime]['cvar_degradation_pct']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    im = ax.imshow(matrix, cmap='RdYlGn', aspect='auto', vmin=-50, vmax=10)\n",
    "    \n",
    "    ax.set_xticks(range(len(regimes_stressed)))\n",
    "    ax.set_xticklabels(['High Vol', 'Extreme'])\n",
    "    ax.set_yticks(range(len(model_names_list)))\n",
    "    ax.set_yticklabels(model_names_list)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(model_names_list)):\n",
    "        for j in range(len(regimes_stressed)):\n",
    "            text = ax.text(j, i, f'{matrix[i, j]:.1f}%',\n",
    "                          ha='center', va='center', color='black', fontsize=12)\n",
    "    \n",
    "    ax.set_title('CVaR Degradation (%) by Model and Regime')\n",
    "    plt.colorbar(im, ax=ax, label='Degradation %')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/regime_degradation_heatmap.pdf', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings:\n",
    "- All models show performance degradation in stressed regimes\n",
    "- Sparse networks may show larger degradation than dense networks\n",
    "- Adversarially trained models are more robust to regime shifts\n",
    "- This highlights the importance of robust training for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_robust_lth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
