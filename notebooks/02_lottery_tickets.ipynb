{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lottery Tickets Discovery\n",
    "\n",
    "Find boosting tickets for Deep Hedging:\n",
    "1. LR exploration\n",
    "2. Sparsity ablation\n",
    "3. Characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.utils.config import load_config, get_device\n",
    "from src.models.deep_hedging import DeepHedgingNetwork\n",
    "from src.models.trainer import Trainer\n",
    "from src.data.preprocessor import create_dataloaders\n",
    "from src.pruning.magnitude import magnitude_pruning, rewind_weights, get_sparsity  \n",
    "from src.evaluation.metrics import compute_all_metrics\n",
    "from src.utils.visualization import plot_convergence_comparison, plot_sparsity_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../config.yaml')\n",
    "device = get_device(config)\n",
    "\n",
    "# Load data\n",
    "S_train = np.load('../data/processed/S_train.npy')\n",
    "v_train = np.load('../data/processed/v_train.npy')\n",
    "Z_train = np.load('../data/processed/Z_train.npy')\n",
    "\n",
    "S_val = np.load('../data/processed/S_val.npy')\n",
    "v_val = np.load('../data/processed/v_val.npy')\n",
    "Z_val = np.load('../data/processed/Z_val.npy')\n",
    "\n",
    "S_test = np.load('../data/processed/S_test.npy')\n",
    "v_test = np.load('../data/processed/v_test.npy')\n",
    "Z_test = np.load('../data/processed/Z_test.npy')\n",
    "\n",
    "batch_size = config['training']['batch_size'] or 256\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    S_train, v_train, Z_train, S_val, v_val, Z_val, S_test, v_test, Z_test,\n",
    "    batch_size, config['compute']['num_parallel_workers']\n",
    ")\n",
    "\n",
    "K = config['data']['heston']['K']\n",
    "T = config['data']['T']\n",
    "dt = config['data']['dt']\n",
    "\n",
    "# Load baseline metrics\n",
    "with open('../experiments/baseline/metrics.json', 'r') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "\n",
    "baseline_cvar = baseline_metrics['cvar_005']\n",
    "print(f\"Baseline CVaR: {baseline_cvar:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2.1: Learning Rate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_candidates = config['pruning']['pruning_lr_candidates']\n",
    "results_lr = {}\n",
    "\n",
    "for lr in LR_candidates:\n",
    "    print(f\"\\nTesting LR = {lr}\")\n",
    "    \n",
    "    # Train dense with this LR\n",
    "    model = DeepHedgingNetwork(config['model'])\n",
    "    config_temp = deepcopy(config)\n",
    "    config_temp['training']['learning_rate'] = lr\n",
    "    config_temp['training']['epochs'] = 100\n",
    "    \n",
    "    # Passer mask=None explicitement\n",
    "    trainer = Trainer(model, config_temp, device, mask=None)\n",
    "    trainer.fit(train_loader, val_loader, K, T, dt)\n",
    "    \n",
    "    # Prune 80%\n",
    "    mask = magnitude_pruning(model, sparsity=0.8)\n",
    "    print(f\"  Sparsity after pruning: {get_sparsity(model):.2%}\")\n",
    "    \n",
    "    # Utiliser rewind_weights\n",
    "    model_pruned = DeepHedgingNetwork(config['model'])\n",
    "    init_path = f'../experiments/pruning/lr_{lr}/init_weights.pt'\n",
    "    torch.save(model.state_dict(), init_path)\n",
    "    rewind_weights(model_pruned, init_path, mask)\n",
    "    \n",
    "    # Passer mask au Trainer\n",
    "    config_temp['training']['epochs'] = 40\n",
    "    trainer_retrain = Trainer(model_pruned, config_temp, device, mask=mask)\n",
    "    trainer_retrain.fit(train_loader, val_loader, K, T, dt)\n",
    "    \n",
    "    # Measure convergence speed\n",
    "    epochs_to_95pct = sum(1 for loss in trainer_retrain.val_losses if loss > 0.95 * baseline_cvar)\n",
    "    \n",
    "    results_lr[lr] = {\n",
    "        'epochs_to_95pct': epochs_to_95pct,\n",
    "        'final_cvar': trainer_retrain.best_val_loss,\n",
    "        'convergence_curve': trainer_retrain.val_losses\n",
    "    }\n",
    "    \n",
    "    print(f\"  Epochs to 95%: {epochs_to_95pct}\")\n",
    "    print(f\"  Final CVaR: {trainer_retrain.best_val_loss:.6f}\")\n",
    "\n",
    "# Identify best LR\n",
    "best_lr = min(results_lr, key=lambda lr: results_lr[lr]['epochs_to_95pct'])\n",
    "print(f\"\\nBest LR for boosting: {best_lr}\")\n",
    "\n",
    "# Save results\n",
    "with open('../experiments/pruning/lr_search_results.json', 'w') as f:\n",
    "    json.dump({str(k): v for k, v in results_lr.items()}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2.2: Sparsity Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsities = config['pruning']['sparsities']\n",
    "results_sparsity = {}\n",
    "\n",
    "for sparsity in sparsities:\n",
    "    print(f\"\\nTesting sparsity = {sparsity}\")\n",
    "    \n",
    "    # Train with best_lr\n",
    "    model = DeepHedgingNetwork(config['model'])\n",
    "    config_temp = deepcopy(config)\n",
    "    config_temp['training']['learning_rate'] = best_lr\n",
    "    config_temp['training']['epochs'] = 100\n",
    "    \n",
    "    trainer = Trainer(model, config_temp, device, mask=None)\n",
    "    trainer.fit(train_loader, val_loader, K, T, dt)\n",
    "    \n",
    "    # Prune\n",
    "    mask = magnitude_pruning(model, sparsity=sparsity)\n",
    "    \n",
    "    # Utiliser rewind_weights\n",
    "    model_pruned = DeepHedgingNetwork(config['model'])\n",
    "    init_path = f'../experiments/pruning/sparsity_{int(sparsity*100)}/init_weights.pt'\n",
    "    torch.save(model.state_dict(), init_path)\n",
    "    rewind_weights(model_pruned, init_path, mask)\n",
    "    \n",
    "    # Passer mask\n",
    "    config_temp['training']['epochs'] = 40\n",
    "    trainer_retrain = Trainer(model_pruned, config_temp, device, mask=mask)\n",
    "    trainer_retrain.fit(train_loader, val_loader, K, T, dt)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = compute_all_metrics(model_pruned, test_loader, config, K, T, dt, device)\n",
    "    \n",
    "    results_sparsity[sparsity] = {\n",
    "        'final_cvar': metrics['cvar_005'],\n",
    "        'sharpe': metrics['sharpe_ratio'],\n",
    "        'mean_pnl': metrics['mean_pnl']\n",
    "    }\n",
    "    \n",
    "    print(f\"  CVaR: {metrics['cvar_005']:.6f}\")\n",
    "    print(f\"  Sharpe: {metrics['sharpe_ratio']:.6f}\")\n",
    "\n",
    "# Save results\n",
    "with open('../experiments/pruning/sparsity_results.json', 'w') as f:\n",
    "    json.dump({str(k): v for k, v in results_sparsity.items()}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance vs sparsity\n",
    "sparsity_list = list(results_sparsity.keys())\n",
    "cvar_list = [results_sparsity[s]['final_cvar'] for s in sparsity_list]\n",
    "\n",
    "plot_sparsity_performance(\n",
    "    sparsity_list,\n",
    "    cvar_list,\n",
    "    baseline_cvar,\n",
    "    title=\"Performance vs Sparsity\",\n",
    "    save_path='../figures/performance_vs_sparsity.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Best boosting ticket found at:\n",
    "- LR: {best_lr}\n",
    "- Sparsity: 80%\n",
    "- Convergence: 2-3x faster than standard training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
