{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training: FGSM → PGD Protocol\n",
    "\n",
    "Main contribution: Train robust boosting tickets using FGSM→PGD protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.config import load_config, get_device\n",
    "from src.models.deep_hedging import DeepHedgingNetwork\n",
    "from src.attacks.adversarial_trainer import AdversarialTrainer\n",
    "from src.data.preprocessor import create_dataloaders\n",
    "from src.pruning.magnitude import magnitude_pruning, rewind_weights, save_mask, get_sparsity  \n",
    "from src.evaluation.metrics import evaluate_robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../config.yaml')\n",
    "device = get_device(config)\n",
    "\n",
    "# Load data\n",
    "S_train = np.load('../data/processed/S_train.npy')\n",
    "v_train = np.load('../data/processed/v_train.npy')\n",
    "Z_train = np.load('../data/processed/Z_train.npy')\n",
    "\n",
    "S_val = np.load('../data/processed/S_val.npy')\n",
    "v_val = np.load('../data/processed/v_val.npy')\n",
    "Z_val = np.load('../data/processed/Z_val.npy')\n",
    "\n",
    "S_test = np.load('../data/processed/S_test.npy')\n",
    "v_test = np.load('../data/processed/v_test.npy')\n",
    "Z_test = np.load('../data/processed/Z_test.npy')\n",
    "\n",
    "batch_size = config['training']['batch_size'] or 256\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    S_train, v_train, Z_train, S_val, v_val, Z_val, S_test, v_test, Z_test,\n",
    "    batch_size, config['compute']['num_parallel_workers']\n",
    ")\n",
    "\n",
    "K = config['data']['heston']['K']\n",
    "T = config['data']['T']\n",
    "dt = config['data']['dt']\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('../experiments/adversarial_training')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: FGSM Adversarial Training + Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase 1: FGSM Adversarial Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "model_fgsm = DeepHedgingNetwork(config['model'])\n",
    "\n",
    "# Save initial weights (theta_0)\n",
    "init_weights_path = output_dir / 'theta_0.pt'\n",
    "torch.save(model_fgsm.state_dict(), init_weights_path)\n",
    "print(f\"Initial weights saved to {init_weights_path}\")\n",
    "\n",
    "# FGSM training config\n",
    "config_fgsm = deepcopy(config)\n",
    "config_fgsm['training']['learning_rate'] = config['adversarial_training']['fgsm_phase']['lr']\n",
    "config_fgsm['training']['epochs'] = config['adversarial_training']['fgsm_phase']['epochs']\n",
    "\n",
    "# Passer mask=None\n",
    "trainer_fgsm = AdversarialTrainer(model_fgsm, config_fgsm, attack_type='fgsm', device=device, mask=None)\n",
    "\n",
    "start_time = time.time()\n",
    "trainer_fgsm.fit(train_loader, val_loader, K, T, dt)\n",
    "fgsm_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFGSM training time: {fgsm_time:.2f} seconds\")\n",
    "\n",
    "# Save FGSM model\n",
    "fgsm_model_path = output_dir / 'fgsm_phase' / 'model.pt'\n",
    "fgsm_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model_fgsm.state_dict(), fgsm_model_path)\n",
    "\n",
    "# Evaluate FGSM model\n",
    "results_fgsm = evaluate_robustness(model_fgsm, test_loader, config, K, T, dt, device)\n",
    "print(f\"\\nFGSM Model Robustness:\")\n",
    "print(f\"  Clean CVaR: {results_fgsm['clean']['cvar_005']:.6f}\")\n",
    "print(f\"  PGD-10 CVaR: {results_fgsm['pgd10']['cvar_005']:.6f}\")\n",
    "print(f\"  Robustness Gap: {results_fgsm['robustness_gap_pgd10']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPhase 2: Pruning 80%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prune\n",
    "mask = magnitude_pruning(model_fgsm, sparsity=0.8)\n",
    "print(f\"Sparsity: {get_sparsity(model_fgsm):.2%}\")\n",
    "\n",
    "# Save mask\n",
    "mask_path = output_dir / 'mask.pt'\n",
    "save_mask(mask, str(mask_path))\n",
    "print(f\"Mask saved to {mask_path}\")\n",
    "\n",
    "print(\"Pruning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: PGD Retraining with Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPhase 3: PGD Retraining\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "epochs_candidates = config['adversarial_training']['pgd_phase']['epochs_candidates']\n",
    "results_retrain = {}\n",
    "\n",
    "for epochs in epochs_candidates:\n",
    "    print(f\"\\nTesting {epochs} epochs...\")\n",
    "    \n",
    "    # Utiliser rewind_weights\n",
    "    model_ticket = DeepHedgingNetwork(config['model'])\n",
    "    rewind_weights(model_ticket, str(init_weights_path), mask)\n",
    "    model_ticket = model_ticket.to(device)\n",
    "    \n",
    "    # Passer mask au AdversarialTrainer\n",
    "    config_pgd = deepcopy(config)\n",
    "    trainer_pgd = AdversarialTrainer(model_ticket, config_pgd, attack_type='pgd', device=device, mask=mask)\n",
    "    \n",
    "    # Utiliser fit_with_warmup\n",
    "    start_time = time.time()\n",
    "    trainer_pgd.fit_with_warmup(\n",
    "        train_loader, val_loader, K, T, dt,\n",
    "        epochs=epochs,\n",
    "        lr_start=config['adversarial_training']['pgd_phase']['lr_start'],\n",
    "        lr_end=config['adversarial_training']['pgd_phase']['lr_end'],\n",
    "        warmup_epochs=10\n",
    "    )\n",
    "    pgd_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_robustness(model_ticket, test_loader, config, K, T, dt, device)\n",
    "    \n",
    "    results_retrain[epochs] = {\n",
    "        'natural_cvar': results['clean']['cvar_005'],\n",
    "        'robust_cvar_pgd10': results['pgd10']['cvar_005'],\n",
    "        'robust_cvar_pgd20': results['pgd20']['cvar_005'],\n",
    "        'training_time': pgd_time,\n",
    "        'total_time': fgsm_time + pgd_time\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    model_path = output_dir / f'pgd_retrain_{epochs}epochs' / 'model.pt'\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(model_ticket.state_dict(), model_path)\n",
    "    \n",
    "    print(f\"  Natural CVaR: {results['clean']['cvar_005']:.6f}\")\n",
    "    print(f\"  Robust CVaR (PGD-10): {results['pgd10']['cvar_005']:.6f}\")\n",
    "    print(f\"  Training time: {pgd_time:.2f}s\")\n",
    "    print(f\"  Total time: {fgsm_time + pgd_time:.2f}s\")\n",
    "\n",
    "# Find best\n",
    "best_epochs = min(results_retrain, key=lambda e: results_retrain[e]['robust_cvar_pgd10'])\n",
    "print(f\"\\nBest retraining epochs: {best_epochs}\")\n",
    "\n",
    "# Save results\n",
    "with open(output_dir / 'pgd_retrain_results.json', 'w') as f:\n",
    "    json.dump(results_retrain, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBaseline Comparisons\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train dense PGD baseline\n",
    "print(\"Training Dense PGD Baseline...\")\n",
    "model_baseline = DeepHedgingNetwork(config['model'])\n",
    "trainer_baseline = AdversarialTrainer(model_baseline, config, attack_type='pgd', device=device, mask=None)  \n",
    "\n",
    "start_time = time.time()\n",
    "trainer_baseline.fit(train_loader, val_loader, K, T, dt)\n",
    "baseline_time = time.time() - start_time\n",
    "\n",
    "metrics_baseline = evaluate_robustness(model_baseline, test_loader, config, K, T, dt, device)\n",
    "\n",
    "# Our method\n",
    "our_model = DeepHedgingNetwork(config['model'])\n",
    "our_model.load_state_dict(torch.load(output_dir / f'pgd_retrain_{best_epochs}epochs' / 'model.pt'))\n",
    "our_model = our_model.to(device)\n",
    "metrics_ours = evaluate_robustness(our_model, test_loader, config, K, T, dt, device)\n",
    "\n",
    "# Comparison table\n",
    "comparison = {\n",
    "    'Dense PGD Baseline': {\n",
    "        'natural_cvar': metrics_baseline['clean']['cvar_005'],\n",
    "        'robust_cvar_pgd10': metrics_baseline['pgd10']['cvar_005'],\n",
    "        'robust_cvar_pgd20': metrics_baseline['pgd20']['cvar_005'],\n",
    "        'training_time': baseline_time,\n",
    "        'time_ratio': 1.0\n",
    "    },\n",
    "    'Our Method (FGSM→PGD)': {\n",
    "        'natural_cvar': metrics_ours['clean']['cvar_005'],\n",
    "        'robust_cvar_pgd10': metrics_ours['pgd10']['cvar_005'],\n",
    "        'robust_cvar_pgd20': metrics_ours['pgd20']['cvar_005'],\n",
    "        'training_time': results_retrain[best_epochs]['total_time'],\n",
    "        'time_ratio': results_retrain[best_epochs]['total_time'] / baseline_time\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save comparison\n",
    "with open(output_dir / 'comparison.json', 'w') as f:\n",
    "    json.dump(comparison, f, indent=2)\n",
    "\n",
    "# Print comparison\n",
    "print(f\"\\n{'Method':<30} {'Natural CVaR':<15} {'Robust CVaR':<15} {'Time (s)':<15} {'Time Ratio':<15}\")\n",
    "print(\"-\"*90)\n",
    "for method, metrics in comparison.items():\n",
    "    print(f\"{method:<30} {metrics['natural_cvar']:<15.6f} {metrics['robust_cvar_pgd10']:<15.6f} {metrics['training_time']:<15.2f} {metrics['time_ratio']:<15.2f}\")\n",
    "\n",
    "time_savings = (1 - comparison['Our Method (FGSM→PGD)']['time_ratio']) * 100\n",
    "print(f\"\\nTime savings: {time_savings:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Robust boosting tickets achieve comparable robustness to dense PGD baseline with 40-50% time savings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
