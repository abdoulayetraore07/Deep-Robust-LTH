# ============================================================================
# DEEP HEDGING + LOTTERY TICKETS + ADVERSARIAL ROBUSTNESS
# Configuration File
# ============================================================================

# Experiment identification
experiment_name: "deep_hedging_lth_adversarial"

# ============================================================================
# CACHING & CHECKPOINTING - NOUVEAU
# ============================================================================
caching:
  enabled: true
  directory: "./cache"
  # 'on': normal caching, 'off': no caching, 'update': overwrite, 'readonly': read only
  mode: "on"

checkpointing:
  enabled: true
  directory: "./checkpoints"
  # Fréquence de sauvegarde (en epochs)
  save_freq: 10
  # Garder les N derniers checkpoints
  keep_last: 3

# ============================================================================
# DATA CONFIGURATION
# ============================================================================
data:
  # Heston model parameters (calibrated to S&P500)
  heston:
    S_0: 100.0        # Initial stock price
    K: 100.0          # Strike (ATM)
    r: 0.02           # Risk-free rate
    mu: 0.05          # Real-world drift
    v_0: 0.0175       # Initial variance (~13.2% vol)
    kappa: 1.5768     # Mean reversion speed
    theta: 0.0398     # Long-term variance (~20% vol)
    xi: 0.5751        # Vol of vol
    rho: -0.5711      # Correlation spot-vol

  # Dataset sizes
  n_train: 100000
  n_val: 15000
  n_test: 15000

  # Simulation parameters
  T: 0.0833           # 1 month in years
  n_steps: 30         # Daily steps
  dt: 0.002777        # T / n_steps

  # Transaction costs
  transaction_cost:
    c_prop: 0.001     # 10 bps proportional cost

  # Random seeds for reproducibility
  seeds:
    train: 42
    val: 43
    test: 44

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  # Input: 5 market features (exogenous) + 3 recurrent features = 8 total
  # But recurrent features are computed during forward pass
  input_dim: 5        # Only exogenous features as input
  recurrent_dim: 3    # delta_prev, pnl_cumulative, trading_volume
  # Total network input = 5 + 3 = 8
  
  # Architecture (from Buehler et al.)
  hidden_dims: [512, 512, 256]
  dropout_rates: [0.2, 0.2, 0.1]  # Pas de dropout par défaut
  use_batch_norm: true           # Pas de batch norm par défaut (comme Buehler)
  
  # Activation
  activation: "relu"

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  # Optimizer
  optimizer_name: "adam"
  learning_rate: 0.001
  weight_decay: 0.0
  
  # Training params
  epochs: 200
  batch_size: 256
  
  # Loss function
  loss_type: "cvar"      # 'cvar', 'entropic', 'mean_variance'
  cvar_alpha: 0.05       # 5% CVaR
  
  # Early stopping
  patience: 30
  min_delta: 1e-6
  
  # Gradient clipping
  clip_grad_norm: 1.0
  
  # Learning rate scheduler
  lr_scheduler: cosine     # 'cosine', 'step', or null
  lr_step_size: 50
  lr_gamma: 0.5

# ============================================================================
# PRUNING CONFIGURATION (Lottery Ticket Hypothesis)
# ============================================================================
pruning:
  # Sparsity levels to test
  sparsities: [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]
  
  # Default target sparsity
  target_sparsity: 0.8
  
  # Pruning method
  method: "magnitude"    # 'magnitude', 'random'
  
  # One-shot vs iterative
  iterative: false
  num_iterations: 5      # If iterative=true
  
  # Exclude output layer from pruning
  exclude_output: true
  
  # Learning rate for retraining (IMPORTANT for boosting tickets)
  # Use LOW LR for pruning phase, standard LR for retraining
  pruning_lr: 0.0001     # Very low for boosting tickets
  retrain_lr: 0.001      # Standard for retraining
  retrain_epochs: 100

# ============================================================================
# ADVERSARIAL ATTACKS CONFIGURATION
# ============================================================================
attacks:
  # FGSM attack
  fgsm:
    epsilon_S: 0.02      # 2% perturbation on S
    epsilon_v: 0.2       # 20% perturbation on v
  
  # PGD attack
  pgd:
    epsilon_S: 0.05      # 5% perturbation on S
    epsilon_v: 0.5       # 50% perturbation on v
    alpha_S: 0.01        # Step size for S
    alpha_v: 0.1         # Step size for v
    num_steps: 10        # PGD iterations
  
  # Stress test attack
  stress:
    epsilon_S: 0.10      # 10% perturbation
    epsilon_v: 1.0       # 100% perturbation

# ============================================================================
# ADVERSARIAL TRAINING CONFIGURATION
# ============================================================================
adversarial_training:
  # Phase 1: FGSM training (to get boosting tickets)
  phase1:
    attack_type: "fgsm"
    epochs: 100
    learning_rate: 0.01
  
  # Phase 2: PGD retraining with warmup
  phase2:
    attack_type: "pgd"
    epochs: 100
    lr_start: 0.001      # Warmup start
    lr_end: 0.01         # Warmup end
    warmup_epochs: 20

# ============================================================================
# REGIME SHIFTS CONFIGURATION
# ============================================================================
regime_shifts:
  # Calm regime (baseline)
  calm:
    theta: 0.0398
    xi: 0.5751
  
  # High volatility regime
  high_vol:
    theta: 0.09          # ~30% long-term vol
    xi: 0.5
  
  # Extreme regime
  extreme:
    theta: 0.16          # ~40% long-term vol
    xi: 0.8

# ============================================================================
# EVALUATION CONFIGURATION
# ============================================================================
evaluation:
  # Metrics to compute
  metrics:
    - mean_pnl
    - std_pnl
    - sharpe_ratio
    - cvar_005
    - cvar_010
    - max_drawdown
    - hedging_error_rmse
    - hedging_error_mae
  
  # Number of bootstrap samples for confidence intervals
  n_bootstrap: 1000

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
logging:
  # TensorBoard
  use_tensorboard: true
  tensorboard_dir: "./runs"
  
  # Console output
  print_freq: 10         # Print every N epochs
  
  # Save figures
  save_figures: true
  figures_dir: "./figures"

# ============================================================================
# COMPUTE CONFIGURATION
# ============================================================================
compute:
  # Device: 'auto', 'cuda', 'cpu'
  device: "auto"
  
  # Number of workers for data loading
  num_workers: 4
  
  # Pin memory for faster GPU transfer
  pin_memory: true